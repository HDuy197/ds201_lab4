{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cài đặt thư viện"
      ],
      "metadata": {
        "id": "svILw3VvxfOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpZhRChuiR2I",
        "outputId": "cd8633c1-0054-4ec7-d144-fc24340a8c0c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d282bc6e6fc98a91997606f3a045c9d1a4bb79d91928f006f23b76e90d522675\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: portalocker, colorama, sacrebleu, rouge_score, evaluate\n",
            "Successfully installed colorama-0.4.6 evaluate-0.4.6 portalocker-3.2.0 rouge_score-0.1.2 sacrebleu-2.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate sacrebleu rouge_score\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import evaluate\n",
        "from collections import Counter\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cấu hình"
      ],
      "metadata": {
        "id": "t4gyA0pExlUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "TRAIN_PATH = 'small-train.json'\n",
        "DEV_PATH   = 'small-dev.json'\n",
        "TEST_PATH  = 'small-test.json'\n",
        "\n",
        "HIDDEN_SIZE = 256\n",
        "N_LAYERS    = 3\n",
        "DROPOUT     = 0.5\n",
        "BATCH_SIZE  = 32\n",
        "LR          = 1e-3\n",
        "N_EPOCHS    = 30"
      ],
      "metadata": {
        "id": "3CWVjLVqiXsb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xử lý data"
      ],
      "metadata": {
        "id": "AuMsWipUxprW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, frequency_threshold=1):\n",
        "        self.itos = {0: \"<pad>\", 1: \"<bos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
        "        self.stoi = {\"<pad>\": 0, \"<bos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "        self.freq_threshold = frequency_threshold\n",
        "        self.pad_idx = 0\n",
        "        self.bos_idx = 1\n",
        "        self.eos_idx = 2\n",
        "        self.unk_idx = 3\n",
        "\n",
        "    def __len__(self): return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenize(text):\n",
        "        return re.findall(r\"\\w+|[^\\w\\s]\", text.lower(), re.UNICODE)\n",
        "\n",
        "    def build_vocab(self, sentence_list):\n",
        "        frequencies = Counter()\n",
        "        idx = 4\n",
        "        for sentence in sentence_list:\n",
        "            for word in self.tokenize(sentence):\n",
        "                frequencies[word] += 1\n",
        "        for word, count in frequencies.items():\n",
        "            if count >= self.freq_threshold:\n",
        "                self.stoi[word] = idx\n",
        "                self.itos[idx] = word\n",
        "                idx += 1\n",
        "        return len(self.itos)\n",
        "\n",
        "    def encode(self, text):\n",
        "        return [self.stoi.get(token, self.unk_idx) for token in self.tokenize(text)]\n",
        "\n",
        "class VocabConfig:\n",
        "    def __init__(self, src_vocab, tgt_vocab):\n",
        "        self.total_src_tokens = len(src_vocab)\n",
        "        self.total_tgt_tokens = len(tgt_vocab)\n",
        "        self.pad_idx = src_vocab.pad_idx\n",
        "        self.bos_idx = src_vocab.bos_idx\n",
        "        self.eos_idx = src_vocab.eos_idx\n",
        "        self.unk_idx = src_vocab.unk_idx\n",
        "\n",
        "class PhoMTDataset(Dataset):\n",
        "    def __init__(self, json_file, limit=None):\n",
        "        self.data = []\n",
        "        if os.path.exists(json_file):\n",
        "            with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                self.data = json.load(f)\n",
        "        if limit: self.data = self.data[:limit]\n",
        "        self.vocab_src = None\n",
        "        self.vocab_tgt = None\n",
        "\n",
        "    def build_vocabs(self):\n",
        "        self.vocab_src = Vocab(1)\n",
        "        self.vocab_tgt = Vocab(1)\n",
        "        src_texts = [item['english'] for item in self.data]\n",
        "        tgt_texts = [item['vietnamese'] for item in self.data]\n",
        "        self.vocab_src.build_vocab(src_texts)\n",
        "        self.vocab_tgt.build_vocab(tgt_texts)\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        src_encoded = self.vocab_src.encode(item['english'])[::-1]\n",
        "        tgt_encoded = self.vocab_tgt.encode(item['vietnamese'])\n",
        "        src_indices = [self.vocab_src.bos_idx] + src_encoded + [self.vocab_src.eos_idx]\n",
        "        tgt_indices = [self.vocab_tgt.bos_idx] + tgt_encoded + [self.vocab_tgt.eos_idx]\n",
        "\n",
        "        return torch.tensor(src_indices), torch.tensor(tgt_indices)\n",
        "\n",
        "class MyCollate:\n",
        "    def __init__(self, pad_idx): self.pad_idx = pad_idx\n",
        "    def __call__(self, batch):\n",
        "        src = [item[0] for item in batch]\n",
        "        trg = [item[1] for item in batch]\n",
        "        src = pad_sequence(src, batch_first=True, padding_value=self.pad_idx)\n",
        "        trg = pad_sequence(trg, batch_first=True, padding_value=self.pad_idx)\n",
        "        return src, trg"
      ],
      "metadata": {
        "id": "IRh-E1P7iYZ6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải data"
      ],
      "metadata": {
        "id": "__AACiGlxreZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PhoMTDataset(TRAIN_PATH, limit=20000)\n",
        "dev_dataset = PhoMTDataset(DEV_PATH, limit=2000)\n",
        "test_dataset = PhoMTDataset(TEST_PATH, limit=2000)\n",
        "\n",
        "train_dataset.build_vocabs()\n",
        "\n",
        "dev_dataset.vocab_src = train_dataset.vocab_src\n",
        "dev_dataset.vocab_tgt = train_dataset.vocab_tgt\n",
        "test_dataset.vocab_src = train_dataset.vocab_src\n",
        "test_dataset.vocab_tgt = train_dataset.vocab_tgt\n",
        "\n",
        "train_dataset.data.sort(key=lambda x: len(x['english'].split()))\n",
        "dev_dataset.data.sort(key=lambda x: len(x['english'].split()))\n",
        "test_dataset.data.sort(key=lambda x: len(x['english'].split()))\n",
        "\n",
        "print(f\"Train: {len(train_dataset)} | Dev: {len(dev_dataset)} | Test: {len(test_dataset)}\")\n",
        "\n",
        "pad_idx = train_dataset.vocab_src.pad_idx\n",
        "collate_fn = MyCollate(pad_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "vocab_config = VocabConfig(train_dataset.vocab_src, train_dataset.vocab_tgt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i40nQKBib0k",
        "outputId": "bea1374b-9264-4964-8c09-367da47ae839"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 20000 | Dev: 2000 | Test: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô hình"
      ],
      "metadata": {
        "id": "n1LKstPGxsy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_hidden = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.fc_cell = nn.Linear(hid_dim * 2, hid_dim)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        n_layers_2, batch, hid = hidden.shape\n",
        "        n_layers = n_layers_2 // 2\n",
        "\n",
        "        hidden = hidden.view(n_layers, 2, batch, hid)\n",
        "        cell = cell.view(n_layers, 2, batch, hid)\n",
        "\n",
        "        hidden = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim=2)\n",
        "        cell = torch.cat((cell[:, 0, :, :], cell[:, 1, :, :]), dim=2)\n",
        "\n",
        "        hidden = torch.tanh(self.fc_hidden(hidden))\n",
        "        cell = torch.tanh(self.fc_cell(cell))\n",
        "\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.Wa = nn.Linear(hid_dim * 2, hid_dim)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        energy = self.Wa(encoder_outputs)\n",
        "\n",
        "        scores = torch.bmm(hidden, energy.permute(0, 2, 1))\n",
        "\n",
        "        return torch.softmax(scores, dim=-1)\n",
        "\n",
        "class LuongDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.fc_out = nn.Linear((hid_dim * 2) + hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(1) # [batch, 1]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        rnn_output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "\n",
        "        a = self.attention(rnn_output, encoder_outputs)\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        concat_input = torch.cat((rnn_output, weighted), dim=2)\n",
        "\n",
        "        prediction = self.fc_out(concat_input).squeeze(1)\n",
        "\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def predict(self, src, max_len=50, bos_idx=1, eos_idx=2):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            batch_size = src.shape[0]\n",
        "            encoder_outputs, hidden, cell = self.encoder(src)\n",
        "            input = torch.tensor([bos_idx] * batch_size).to(self.device)\n",
        "            outputs = []\n",
        "\n",
        "            for _ in range(max_len):\n",
        "                output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "                pred_token = output.argmax(1)\n",
        "                outputs.append(pred_token.unsqueeze(1))\n",
        "                input = pred_token\n",
        "\n",
        "            return torch.cat(outputs, dim=1)"
      ],
      "metadata": {
        "id": "X-GwkbAnigSG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tạo Model"
      ],
      "metadata": {
        "id": "qS5tC9NPxuaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn = LuongAttention(HIDDEN_SIZE)\n",
        "enc = Encoder(vocab_config.total_src_tokens, HIDDEN_SIZE, HIDDEN_SIZE, N_LAYERS, DROPOUT)\n",
        "dec = LuongDecoder(vocab_config.total_tgt_tokens, HIDDEN_SIZE, HIDDEN_SIZE, N_LAYERS, DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name and param.dim() > 1:\n",
        "            nn.init.xavier_uniform_(param.data)\n",
        "        elif 'bias' in name:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab_config.pad_idx)"
      ],
      "metadata": {
        "id": "by03vNjgiiKk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning"
      ],
      "metadata": {
        "id": "9MB8Yw5xxvwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in loader:\n",
        "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, tgt)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "print(f\"Huấn luyện {N_EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    end_time = time.time()\n",
        "    print(f\"Epoch {epoch+1:02} | Time: {end_time - start_time:.0f}s | Train Loss: {train_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc6EOa4hijgG",
        "outputId": "2389dd1e-31af-4a77-c180-3718e617ba5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Huấn luyện 30 epochs\n",
            "Epoch 01 | Time: 88s | Train Loss: 5.9621\n",
            "Epoch 02 | Time: 84s | Train Loss: 5.6268\n",
            "Epoch 03 | Time: 83s | Train Loss: 5.3212\n",
            "Epoch 04 | Time: 82s | Train Loss: 5.0128\n",
            "Epoch 05 | Time: 84s | Train Loss: 4.7633\n",
            "Epoch 06 | Time: 83s | Train Loss: 4.5365\n",
            "Epoch 07 | Time: 84s | Train Loss: 4.3239\n",
            "Epoch 08 | Time: 83s | Train Loss: 4.1454\n",
            "Epoch 09 | Time: 83s | Train Loss: 3.9870\n",
            "Epoch 10 | Time: 83s | Train Loss: 3.8446\n",
            "Epoch 11 | Time: 83s | Train Loss: 3.7112\n",
            "Epoch 12 | Time: 83s | Train Loss: 3.6069\n",
            "Epoch 13 | Time: 83s | Train Loss: 3.5028\n",
            "Epoch 14 | Time: 83s | Train Loss: 3.4070\n",
            "Epoch 15 | Time: 83s | Train Loss: 3.3469\n",
            "Epoch 16 | Time: 83s | Train Loss: 3.2679\n",
            "Epoch 17 | Time: 84s | Train Loss: 3.1948\n",
            "Epoch 18 | Time: 83s | Train Loss: 3.1311\n",
            "Epoch 19 | Time: 82s | Train Loss: 3.0838\n",
            "Epoch 20 | Time: 82s | Train Loss: 3.0336\n",
            "Epoch 21 | Time: 82s | Train Loss: 2.9780\n",
            "Epoch 22 | Time: 82s | Train Loss: 2.9373\n",
            "Epoch 23 | Time: 82s | Train Loss: 2.8735\n",
            "Epoch 24 | Time: 82s | Train Loss: 2.8195\n",
            "Epoch 25 | Time: 82s | Train Loss: 2.7765\n",
            "Epoch 26 | Time: 84s | Train Loss: 2.7420\n",
            "Epoch 27 | Time: 82s | Train Loss: 2.7020\n",
            "Epoch 28 | Time: 82s | Train Loss: 2.6758\n",
            "Epoch 29 | Time: 82s | Train Loss: 2.6449\n",
            "Epoch 30 | Time: 82s | Train Loss: 2.6050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đánh giá"
      ],
      "metadata": {
        "id": "h9mQvDPKxxdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def calculate_rouge(model, loader, dataset):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    refs = []\n",
        "\n",
        "    print(\"Tính toán ROUGE-L trên tập Test\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in tqdm(loader):\n",
        "            src = src.to(DEVICE)\n",
        "\n",
        "            batch_preds = model.predict(src)\n",
        "\n",
        "            bs = src.shape[0]\n",
        "\n",
        "            if batch_preds.numel() == 0:\n",
        "                continue\n",
        "\n",
        "            for i in range(bs):\n",
        "                if i >= len(batch_preds): break\n",
        "\n",
        "                pred_tokens = []\n",
        "                for idx in batch_preds[i]:\n",
        "                    if idx == dataset.vocab_tgt.eos_idx: break\n",
        "                    pred_tokens.append(dataset.vocab_tgt.itos[idx.item()])\n",
        "\n",
        "                tgt_tokens = []\n",
        "                for idx in tgt[i]:\n",
        "                    if idx == dataset.vocab_tgt.eos_idx: break\n",
        "                    if idx not in [dataset.vocab_tgt.bos_idx, dataset.vocab_tgt.pad_idx]:\n",
        "                        tgt_tokens.append(dataset.vocab_tgt.itos[idx.item()])\n",
        "\n",
        "                preds.append(\" \".join(pred_tokens))\n",
        "                refs.append(\" \".join(tgt_tokens))\n",
        "\n",
        "    results = rouge.compute(predictions=preds, references=refs)\n",
        "    return results\n",
        "\n",
        "scores = calculate_rouge(model, test_loader, test_dataset)\n",
        "print(f\"KẾT QUẢ BÀI 3 (ROUGE-L): {scores['rougeL']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8lqFyC6ikmY",
        "outputId": "a2fa4ad9-11ae-4470-904b-cafcceb4b3d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tính toán ROUGE-L trên tập Test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:06<00:00, 10.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KẾT QUẢ BÀI 3 (ROUGE-L): 0.4056\n"
          ]
        }
      ]
    }
  ]
}