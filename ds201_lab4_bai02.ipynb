{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1a18f49dec640d0ab74093f7c1ab306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edb2906487aa4e7fae43b5e64f085951",
              "IPY_MODEL_e2327a49ff9f41bcab40497934bb235b",
              "IPY_MODEL_f52a619b2c2a49c2a2a915c8ee43fd94"
            ],
            "layout": "IPY_MODEL_b074206cca13440384db32531fd3ecdc"
          }
        },
        "edb2906487aa4e7fae43b5e64f085951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcc4608889d24fcdab13c19b9d5e9f88",
            "placeholder": "​",
            "style": "IPY_MODEL_044d3484b7df4f11b4c91b2dcf64da46",
            "value": "Downloading builder script: "
          }
        },
        "e2327a49ff9f41bcab40497934bb235b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff8e23b14e7411480c176a9cc4e8f1b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0533e24b03843c3b314e843eac8a580",
            "value": 1
          }
        },
        "f52a619b2c2a49c2a2a915c8ee43fd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13b23d56cdff498ebc95c69c94655d25",
            "placeholder": "​",
            "style": "IPY_MODEL_969f2e117ff347a794fa4748df045fc8",
            "value": " 6.14k/? [00:00&lt;00:00, 516kB/s]"
          }
        },
        "b074206cca13440384db32531fd3ecdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcc4608889d24fcdab13c19b9d5e9f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044d3484b7df4f11b4c91b2dcf64da46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ff8e23b14e7411480c176a9cc4e8f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f0533e24b03843c3b314e843eac8a580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13b23d56cdff498ebc95c69c94655d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969f2e117ff347a794fa4748df045fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cài đặt thư viện"
      ],
      "metadata": {
        "id": "PaO16lTHw7FV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wxvoQQqBcPXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c42c1940-d363-4288-f61e-430c2b37e413",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=566c2283ecb835f90c51905d92f5639d3eafd1beb92837b83a0bf97188e8bcbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: portalocker, colorama, sacrebleu, rouge_score, evaluate\n",
            "Successfully installed colorama-0.4.6 evaluate-0.4.6 portalocker-3.2.0 rouge_score-0.1.2 sacrebleu-2.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate sacrebleu rouge_score\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import evaluate\n",
        "from collections import Counter\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cấu hình"
      ],
      "metadata": {
        "id": "PsTK1_Fkw5eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "TRAIN_PATH = 'small-train.json'\n",
        "DEV_PATH   = 'small-dev.json'\n",
        "TEST_PATH  = 'small-test.json'\n",
        "\n",
        "HIDDEN_SIZE = 256\n",
        "N_LAYERS    = 3\n",
        "DROPOUT     = 0.5\n",
        "BATCH_SIZE  = 32\n",
        "LR          = 1e-3\n",
        "N_EPOCHS    = 30"
      ],
      "metadata": {
        "id": "f2eF7eZHck9Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xử lý data"
      ],
      "metadata": {
        "id": "k03FcBy8xEwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, frequency_threshold=1):\n",
        "        self.itos = {0: \"<pad>\", 1: \"<bos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
        "        self.stoi = {\"<pad>\": 0, \"<bos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "        self.freq_threshold = frequency_threshold\n",
        "        self.pad_idx = 0\n",
        "        self.bos_idx = 1\n",
        "        self.eos_idx = 2\n",
        "        self.unk_idx = 3\n",
        "\n",
        "    def __len__(self): return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenize(text):\n",
        "        return re.findall(r\"\\w+|[^\\w\\s]\", text.lower(), re.UNICODE)\n",
        "\n",
        "    def build_vocab(self, sentence_list):\n",
        "        frequencies = Counter()\n",
        "        idx = 4\n",
        "        for sentence in sentence_list:\n",
        "            for word in self.tokenize(sentence):\n",
        "                frequencies[word] += 1\n",
        "        for word, count in frequencies.items():\n",
        "            if count >= self.freq_threshold:\n",
        "                self.stoi[word] = idx\n",
        "                self.itos[idx] = word\n",
        "                idx += 1\n",
        "        return len(self.itos)\n",
        "\n",
        "    def encode(self, text):\n",
        "        return [self.stoi.get(token, self.unk_idx) for token in self.tokenize(text)]\n",
        "\n",
        "class VocabConfig:\n",
        "    def __init__(self, src_vocab, tgt_vocab):\n",
        "        self.total_src_tokens = len(src_vocab)\n",
        "        self.total_tgt_tokens = len(tgt_vocab)\n",
        "        self.pad_idx = src_vocab.pad_idx\n",
        "        self.bos_idx = src_vocab.bos_idx\n",
        "        self.eos_idx = src_vocab.eos_idx\n",
        "        self.unk_idx = src_vocab.unk_idx\n",
        "\n",
        "class PhoMTDataset(Dataset):\n",
        "    def __init__(self, json_file, limit=None):\n",
        "        self.data = []\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            self.data = json.load(f)\n",
        "        if limit: self.data = self.data[:limit]\n",
        "        self.vocab_src = None\n",
        "        self.vocab_tgt = None\n",
        "\n",
        "    def build_vocabs(self):\n",
        "        self.vocab_src = Vocab(1)\n",
        "        self.vocab_tgt = Vocab(1)\n",
        "        src_texts = [item['english'] for item in self.data]\n",
        "        tgt_texts = [item['vietnamese'] for item in self.data]\n",
        "        self.vocab_src.build_vocab(src_texts)\n",
        "        self.vocab_tgt.build_vocab(tgt_texts)\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        src_encoded = self.vocab_src.encode(item['english'])[::-1]\n",
        "        tgt_encoded = self.vocab_tgt.encode(item['vietnamese'])\n",
        "        src_indices = [self.vocab_src.bos_idx] + src_encoded + [self.vocab_src.eos_idx]\n",
        "        tgt_indices = [self.vocab_tgt.bos_idx] + tgt_encoded + [self.vocab_tgt.eos_idx]\n",
        "\n",
        "        return torch.tensor(src_indices), torch.tensor(tgt_indices)\n",
        "\n",
        "class MyCollate:\n",
        "    def __init__(self, pad_idx): self.pad_idx = pad_idx\n",
        "    def __call__(self, batch):\n",
        "        src = [item[0] for item in batch]\n",
        "        trg = [item[1] for item in batch]\n",
        "        src = pad_sequence(src, batch_first=True, padding_value=self.pad_idx)\n",
        "        trg = pad_sequence(trg, batch_first=True, padding_value=self.pad_idx)\n",
        "        return src, trg"
      ],
      "metadata": {
        "id": "3i77jQzIcmdC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải data"
      ],
      "metadata": {
        "id": "qRWi62BUxGf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PhoMTDataset(TRAIN_PATH, limit=20000)\n",
        "dev_dataset = PhoMTDataset(DEV_PATH, limit=2000)\n",
        "test_dataset = PhoMTDataset(TEST_PATH, limit=2000)\n",
        "\n",
        "train_dataset.build_vocabs()\n",
        "\n",
        "dev_dataset.vocab_src = train_dataset.vocab_src\n",
        "dev_dataset.vocab_tgt = train_dataset.vocab_tgt\n",
        "test_dataset.vocab_src = train_dataset.vocab_src\n",
        "test_dataset.vocab_tgt = train_dataset.vocab_tgt\n",
        "\n",
        "train_dataset.data.sort(key=lambda x: len(x['english'].split()))\n",
        "dev_dataset.data.sort(key=lambda x: len(x['english'].split()))\n",
        "test_dataset.data.sort(key=lambda x: len(x['english'].split()))\n",
        "\n",
        "print(f\"Train: {len(train_dataset)} | Dev: {len(dev_dataset)} | Test: {len(test_dataset)}\")\n",
        "\n",
        "pad_idx = train_dataset.vocab_src.pad_idx\n",
        "collate_fn = MyCollate(pad_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "vocab_config = VocabConfig(train_dataset.vocab_src, train_dataset.vocab_tgt)"
      ],
      "metadata": {
        "id": "WaW45BF3cn_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dafb5c0b-be63-4793-9b03-198670d400bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 20000 | Dev: 2000 | Test: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô hình"
      ],
      "metadata": {
        "id": "UH9t0XY7xOkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_hidden = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.fc_cell = nn.Linear(hid_dim * 2, hid_dim)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        n_layers_2, batch, hid = hidden.shape\n",
        "        n_layers = n_layers_2 // 2\n",
        "\n",
        "        hidden = hidden.view(n_layers, 2, batch, hid)\n",
        "        cell = cell.view(n_layers, 2, batch, hid)\n",
        "\n",
        "        hidden = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim=2)\n",
        "        cell = torch.cat((cell[:, 0, :, :], cell[:, 1, :, :]), dim=2)\n",
        "\n",
        "        hidden = torch.tanh(self.fc_hidden(hidden))\n",
        "        cell = torch.tanh(self.fc_cell(cell))\n",
        "\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear((hid_dim * 2) + hid_dim, hid_dim)\n",
        "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM((hid_dim * 2) + emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc_out = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        a = self.attention(hidden[-1], encoder_outputs)\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "\n",
        "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=2))\n",
        "        prediction = prediction.squeeze(1)\n",
        "\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "\n",
        "            top1 = output.argmax(1)\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def predict(self, src, max_len=50, bos_idx=1, eos_idx=2):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            batch_size = src.shape[0]\n",
        "            encoder_outputs, hidden, cell = self.encoder(src)\n",
        "            input = torch.tensor([bos_idx] * batch_size).to(self.device)\n",
        "            outputs = []\n",
        "\n",
        "            for _ in range(max_len):\n",
        "                output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "                pred_token = output.argmax(1)\n",
        "                outputs.append(pred_token.unsqueeze(1))\n",
        "                input = pred_token\n",
        "\n",
        "            return torch.cat(outputs, dim=1)"
      ],
      "metadata": {
        "id": "yLtpTCV7cp5y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tạo Model"
      ],
      "metadata": {
        "id": "LufbbrFCxQab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn = Attention(HIDDEN_SIZE)\n",
        "\n",
        "enc = Encoder(vocab_config.total_src_tokens, HIDDEN_SIZE, HIDDEN_SIZE, N_LAYERS, DROPOUT)\n",
        "\n",
        "dec = Decoder(vocab_config.total_tgt_tokens, HIDDEN_SIZE, HIDDEN_SIZE, N_LAYERS, DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name and param.dim() > 1:\n",
        "            nn.init.xavier_uniform_(param.data)\n",
        "        elif 'bias' in name:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab_config.pad_idx)"
      ],
      "metadata": {
        "id": "XHJtzFX_cuTY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning"
      ],
      "metadata": {
        "id": "zLOJIuq6xVwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in loader:\n",
        "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, tgt)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "print(f\"Huấn luyện {N_EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    end_time = time.time()\n",
        "    print(f\"Epoch {epoch+1:02} | Time: {end_time - start_time:.0f}s | Train Loss: {train_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8zfcns4wcv0t",
        "outputId": "c3099634-d1a0-48fe-e31c-2a0a4e2c2126"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Huấn luyện 30 epochs\n",
            "Epoch 01 | Time: 96s | Train Loss: 5.8136\n",
            "Epoch 02 | Time: 91s | Train Loss: 5.2424\n",
            "Epoch 03 | Time: 90s | Train Loss: 4.8760\n",
            "Epoch 04 | Time: 90s | Train Loss: 4.5859\n",
            "Epoch 05 | Time: 87s | Train Loss: 4.3806\n",
            "Epoch 06 | Time: 87s | Train Loss: 4.1915\n",
            "Epoch 07 | Time: 88s | Train Loss: 4.0151\n",
            "Epoch 08 | Time: 87s | Train Loss: 3.8783\n",
            "Epoch 09 | Time: 87s | Train Loss: 3.7405\n",
            "Epoch 10 | Time: 87s | Train Loss: 3.6087\n",
            "Epoch 11 | Time: 87s | Train Loss: 3.5226\n",
            "Epoch 12 | Time: 87s | Train Loss: 3.4135\n",
            "Epoch 13 | Time: 87s | Train Loss: 3.3239\n",
            "Epoch 14 | Time: 88s | Train Loss: 3.2554\n",
            "Epoch 15 | Time: 87s | Train Loss: 3.1837\n",
            "Epoch 16 | Time: 87s | Train Loss: 3.1187\n",
            "Epoch 17 | Time: 87s | Train Loss: 3.0627\n",
            "Epoch 18 | Time: 87s | Train Loss: 3.0031\n",
            "Epoch 19 | Time: 88s | Train Loss: 2.9329\n",
            "Epoch 20 | Time: 87s | Train Loss: 2.8804\n",
            "Epoch 21 | Time: 88s | Train Loss: 2.8401\n",
            "Epoch 22 | Time: 87s | Train Loss: 2.8071\n",
            "Epoch 23 | Time: 87s | Train Loss: 2.7611\n",
            "Epoch 24 | Time: 87s | Train Loss: 2.7211\n",
            "Epoch 25 | Time: 87s | Train Loss: 2.6848\n",
            "Epoch 26 | Time: 86s | Train Loss: 2.6437\n",
            "Epoch 27 | Time: 87s | Train Loss: 2.6064\n",
            "Epoch 28 | Time: 87s | Train Loss: 2.5790\n",
            "Epoch 29 | Time: 87s | Train Loss: 2.5576\n",
            "Epoch 30 | Time: 86s | Train Loss: 2.5327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đánh giá"
      ],
      "metadata": {
        "id": "QU0WBoA4xXnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def calculate_rouge(model, loader, dataset):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    refs = []\n",
        "\n",
        "    print(\"Tính toán ROUGE-L trên tập Test\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in tqdm(loader):\n",
        "            src = src.to(DEVICE)\n",
        "\n",
        "            batch_preds = model.predict(src)\n",
        "\n",
        "            bs = src.shape[0]\n",
        "\n",
        "            if batch_preds.numel() == 0:\n",
        "                continue\n",
        "\n",
        "            for i in range(bs):\n",
        "                if i >= len(batch_preds): break\n",
        "\n",
        "                pred_tokens = []\n",
        "                for idx in batch_preds[i]:\n",
        "                    if idx == dataset.vocab_tgt.eos_idx: break\n",
        "                    pred_tokens.append(dataset.vocab_tgt.itos[idx.item()])\n",
        "\n",
        "                tgt_tokens = []\n",
        "                for idx in tgt[i]:\n",
        "                    if idx == dataset.vocab_tgt.eos_idx: break\n",
        "                    if idx not in [dataset.vocab_tgt.bos_idx, dataset.vocab_tgt.pad_idx]:\n",
        "                        tgt_tokens.append(dataset.vocab_tgt.itos[idx.item()])\n",
        "\n",
        "                preds.append(\" \".join(pred_tokens))\n",
        "                refs.append(\" \".join(tgt_tokens))\n",
        "\n",
        "    results = rouge.compute(predictions=preds, references=refs)\n",
        "    return results\n",
        "\n",
        "scores = calculate_rouge(model, test_loader, test_dataset)\n",
        "print(f\"KẾT QUẢ BÀI 2 (ROUGE-L): {scores['rougeL']:.4f}\")"
      ],
      "metadata": {
        "id": "5UJF4idccxPl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "a1a18f49dec640d0ab74093f7c1ab306",
            "edb2906487aa4e7fae43b5e64f085951",
            "e2327a49ff9f41bcab40497934bb235b",
            "f52a619b2c2a49c2a2a915c8ee43fd94",
            "b074206cca13440384db32531fd3ecdc",
            "dcc4608889d24fcdab13c19b9d5e9f88",
            "044d3484b7df4f11b4c91b2dcf64da46",
            "6ff8e23b14e7411480c176a9cc4e8f1b",
            "f0533e24b03843c3b314e843eac8a580",
            "13b23d56cdff498ebc95c69c94655d25",
            "969f2e117ff347a794fa4748df045fc8"
          ]
        },
        "outputId": "877048e5-b342-48fa-bf64-5193ce08095b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1a18f49dec640d0ab74093f7c1ab306"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tính toán ROUGE-L trên tập Test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:05<00:00, 10.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KẾT QUẢ BÀI 2 (ROUGE-L): 0.3892\n"
          ]
        }
      ]
    }
  ]
}